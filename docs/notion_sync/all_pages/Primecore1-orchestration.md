# Primecore1-orchestration

*Synced from Notion*

ğŸ”— [View in Notion](https://notion.so/2a3c730ec2c880a3bf4cf4b0a8da956b)

---

# Primecore1 User Guide

Main interface-

http://141.136.35.51:8080/dashboard/

ğŸ¯

System Overview

PrimeCore1 is your complete AI infrastructure platform running on Ubuntu 24.04.2 LTS with 8 cores, 32GB RAM, and 400GB storage. It provides a comprehensive suite of AI services, development tools, and data management capabilities.

Server Details:

â€¢ URL: primecore1.site

â€¢ IP: 141.136.35.51

â€¢ Network: Docker network primecore1 (172.20.0.0/16)

ğŸŒ

Service Access Points

Primary AI Interfaces

AI Services

Data & Storage

Infrastructure & Monitoring

ğŸ“

Updated Root Structure

/root-primecore1/

â”œâ”€â”€ infrastructure/Â Â # Core infrastructure

â”‚Â Â Â â”œâ”€â”€ caddy/Â  Â  Â  Â Â # NEW: Simple reverse proxy

â”‚Â Â Â â”œâ”€â”€ vault/Â Â  Â  Â  Â  Â  Â  Â Â # Secrets management

â”‚Â Â Â â”œâ”€â”€ consul/Â  Â  Â  Â  Â  Â  Â Â # Service discovery

â”‚Â Â Â â”œâ”€â”€ monitoring/Â  Â  Â Â # Prometheus + Grafana

â”‚Â Â Â â””â”€â”€ networking/Â  Â  Â Â # Docker network config

â”œâ”€â”€ data-layer/Â Â  Â  Â Â # Data storage and manag

â”œâ”€â”€ ai-services/Â Â  Â  Â  Â  Â  Â Â # AI and ML services

â”‚Â Â Â â”œâ”€â”€ autogen-studio/Â Â  Â Â # NEW: Multi-agent

â”‚Â Â Â â”œâ”€â”€ ollama/Â Â  Â  Â  Â  Â  Â Â # LLM server

â”‚Â Â Â â”œâ”€â”€ openwebui/Â  Â  Â  Â  Â Â # Primary AI interface

â”‚Â Â Â â””â”€â”€ n8nÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â Â # automation

â”œâ”€â”€ control/Â  Â  Â  Â Â # Management and autom

â”œâ”€â”€ userspace/Â  Â  Â  Â  Â Â # User projects and data

â”œâ”€â”€ DEPLOYMENT_COMPLETE.md

â””â”€â”€ ACCESS_POINTS.mdÂ Â  Â  Â  Â Â # Service access information

ğŸ—ï¸

Updated Infrastructure Layer

Caddy (Reverse Proxy)

/root-primecore1/infrastructure/caddy/

â”œâ”€â”€ docker-compose.ymlÂ Â  Â  Â Â # Simple Caddy configuration

â”œâ”€â”€ CaddyfileÂ Â  Â  Â  Â  Â  Â  Â Â # Routing rules

â””â”€â”€ logs/Â Â  Â  Â  Â  Â  Â  Â  Â  Â Â # Access logs

Key Benefits:

â€¢ âœ… Simple configuration (no complex SSL setup)

â€¢ âœ… Automatic HTTPS (when needed)

â€¢ âœ… Path-based routing

â€¢ âœ… Better performance than Traefik

Other Infrastructure Components

/root-primecore1/infrastructure/

â”œâ”€â”€ vault/

â”‚Â Â Â â”œâ”€â”€ docker-compose.ymlÂ Â  Â  Â Â # HashiCorp Vault

â”‚Â Â Â â”œâ”€â”€ vault.hclÂ Â  Â  Â  Â  Â  Â  Â Â # Vault configuration

â”‚Â Â Â â””â”€â”€ vault-keys.jsonÂ Â  Â  Â  Â Â # Vault initialization keys (secure!)

â”œâ”€â”€ consul/

â”‚Â Â Â â”œâ”€â”€ docker-compose.ymlÂ Â  Â  Â Â # Service discovery

â”‚Â Â Â â””â”€â”€ consul.hclÂ  Â  Â  Â  Â  Â  Â Â # Consul configuration

â”œâ”€â”€ monitoring/

â”‚Â Â Â â”œâ”€â”€ docker-compose.ymlÂ Â  Â  Â Â # Prometheus + Grafana

â”‚Â Â Â â””â”€â”€ prometheus.ymlÂ  Â  Â  Â  Â Â # Metrics configuration

â””â”€â”€ networking/

â””â”€â”€ network-config.ymlÂ Â  Â  Â Â # Docker network definitions

ğŸ¤–

Enhanced AI Services Layer

New AutoGen Studio

/root-primecore1/ai-services/autogen-studio/

â”œâ”€â”€ docker-compose.ymlÂ Â  Â  Â Â # Multi-agent platform

â”œâ”€â”€ workspace/Â  Â  Â  Â  Â  Â  Â Â # Agent configurations

â”œâ”€â”€ sessions/Â  Â  Â  Â  Â  Â  Â Â # Chat sessions

â””â”€â”€ skills/Â  Â  Â  Â  Â  Â  Â  Â Â # Custom agent skills

Capabilities:

â€¢ ğŸ¤–

â€¢ Multi-agent workflows

â€¢ - Coordinate multiple AI agents

â€¢ ğŸ”§

â€¢ Local LLM integration

â€¢ - Uses your Ollama models

â€¢ ğŸ¨

â€¢ Visual workflow builder

â€¢ - Drag & drop agent design

â€¢ ğŸ’¬

â€¢ Real-time collaboration

â€¢ - Multiple agents working together

Core AI Services

/root-primecore1/ai-services/

â”œâ”€â”€ ollama/

â”‚Â Â Â â””â”€â”€ docker-compose.ymlÂ Â  Â  Â Â # LLM server (OpenAI API compatible)

â”œâ”€â”€ openwebui/

â”‚Â Â Â â””â”€â”€ docker-compose.ymlÂ Â  Â Â # Primary AI

â”œâ”€â”€ whisper/

â”‚Â Â Â â””â”€â”€ docker-compose.ymlÂ  Â Â # Speech-to-text

â”œâ”€â”€ n8n/

â”‚Â Â Â â””â”€â”€ docker-compose.ymlÂ Â  Â Â # Workflow auto

â”œâ”€â”€ mlflow/

â”‚Â Â Â â”œâ”€â”€ docker-compose.ymlÂ Â  Â  Â Â # ML experiment tracking

â”‚Â Â Â â””â”€â”€ mlruns/Â Â  Â  Â  Â  Â  Â  Â  Â Â # Experiment data

â”œâ”€â”€ minio/

â”‚Â Â Â â””â”€â”€ docker-compose.ymlÂ  Â Â # Object storage

â””â”€â”€ llamaparse/

â”œâ”€â”€ docker-compose.ymlÂ Â  Â Â # Document pdf

â”œâ”€â”€ app/

â”‚Â Â Â â””â”€â”€ main.pyÂ Â  Â  Â Â # LlamaParse application

â”œâ”€â”€ uploads/Â  Â  Â  Â  Â  Â  Â  Â Â # Document uploads

â””â”€â”€ output/Â Â  Â  Â  Â  Â  Â  Â  Â Â # Processed documents

ğŸ§ 

Available AI Models

Large Language Models (via Ollama)

# Available models - optimized selection

mistral:7b-instructÂ Â  Â Â # Best for: General chat, reasoning

deepseek-coder:6.7bÂ  Â Â # Best for: Programming, code generation

llama3.2:3bÂ  Â  Â  Â  Â  Â Â # Best for: Quick responses, lightweight

phi:2.7bÂ Â  Â  Â  Â  Â  Â  Â Â # Best for: Fast inference, efficiency